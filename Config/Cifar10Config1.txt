#Comment#

#NON_LINEARITY = NL_SIGMOID , NL_TANH , NL_RELU#

IS_GRADIENT_CHECKING = false;   #is true when debug#
BATCH_SIZE = 128;               #test image size should be divided with no remainder#

CHANNELS = 3;                   #1, 3, 4#
CROP = 4;                       #0<= crop <=imgSize#
SCALE = 0.0;                    #13% of ImgSize#
ROTATION = 0.0;                 #angle#
DISTORTION = 0.0;               #just for mnist#
SHOWIMAGE = false;              #show the images after transformation#
HORIZONTAL = true;              #horizontal reflection#
TEST_EPOCH = 10;                #the period to get the test dataset's error rate#
WHITE_NOISE = 0.01;

[
LAYER = CONV;
NAME  = conv1;
INPUT = data;
KERNEL_SIZE = 5;
PADDING = 2;
KERNEL_AMOUNT = 64;
COMBINE_FEATRUE_MAPS = 1;       #According to paper "notes on Convolutional Neural NetWorks#
WEIGHT_DECAY = 1e-6;
initW = 1.0;
initType = Bernoulli;           #Gaussian, Bernoulli#
]

[
LAYER = POOLING;
NAME  = pooling1;
INPUT = conv1;
SIZE = 2;
SKIP = 2;
NON_LINEARITY = NL_RELU;
]

[
LAYER = LRN;
NAME = lrn1;
INPUT = pooling1;
LRN_K = 2.0;
LRN_N = 4;
LRN_ALPHA = 0.000125;
LRN_BALTA = 0.75;
]

[  
LAYER = NIN;
NAME  = nin1;
INPUT = lrn1;
WEIGHT_DECAY = 1e-4;
]

[  
LAYER = CONV;
NAME  = conv2;
INPUT = nin1;
KERNEL_SIZE = 5;
PADDING = 2;
KERNEL_AMOUNT = 64;
COMBINE_FEATRUE_MAPS = 1;       #According to paper "notes on Convolutional Neural NetWorks#
WEIGHT_DECAY = 1e-6;
initW = 0.9;
initType = Bernoulli;           #Gaussian, Bernoulli#
]


[
LAYER = LRN;
NAME = lrn2;
INPUT = conv2;
LRN_K = 2.0;
LRN_N = 4;
LRN_ALPHA = 0.000125;
LRN_BALTA = 0.75;
]

[
LAYER = POOLING;
NAME  = pooling2;
INPUT = lrn2;
SIZE = 2;
SKIP = 2;
NON_LINEARITY = NL_RELU;
]


[  
LAYER = LOCAL;
NAME  = local1;
INPUT = pooling2;
KERNEL_SIZE = 3;
KERNEL_AMOUNT = 64;
COMBINE_FEATRUE_MAPS = 1;       #According to paper "notes on Convolutional Neural NetWorks#
WEIGHT_DECAY = 1e-8;
initW = 0.9;
initType = Gaussian;           #Gaussian, Bernoulli#
]

[
LAYER = FC;
NAME  = fc1;
INPUT = local1;
NUM_FULLCONNECT_NEURONS = 512;
WEIGHT_DECAY = 1e-4;
DROPCONNECT_RATE = 0.0;
initW = 0.12;
NON_LINEARITY = NL_RELU;
initType = Bernoulli;           #Gaussian, Bernoulli#
]

[  
LAYER = NIN;
NAME  = nin3;
INPUT = fc1;
WEIGHT_DECAY = 1e-4;
]


[
LAYER = SOFTMAX;
NAME = softmax1;
INPUT = nin3;
NUM_CLASSES = 10;
WEIGHT_DECAY = 1e-4;
initW = 0.1;
initType = Bernoulli;           #Gaussian, Bernoulli#
]
